{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n",
    "        self.audio = audio\n",
    "        self.ffT_length = windowLength\n",
    "        self.window_length = windowLength\n",
    "        self.overlap = overlap\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window = scipy.signal.hamming(self.window_length, sym=False)\n",
    "\n",
    "    def get_stft_spectrogram(self):\n",
    "        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n",
    "                            window=self.window, center=True)\n",
    "\n",
    "    def get_audio_from_stft_spectrogram(self, stft_features):\n",
    "        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n",
    "                             window=self.window, center=True)\n",
    "\n",
    "    def get_mel_spectrogram(self):\n",
    "        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n",
    "                                           n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n",
    "\n",
    "    def get_audio_from_mel_spectrogram(self, M):\n",
    "        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length, hop_length=self.overlap,\n",
    "                                             win_length=self.window_length, window=self.window,\n",
    "                                             center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowLength = 256\n",
    "overlap      = round(0.25 * windowLength) # overlap of 75%\n",
    "ffTLength    = windowLength\n",
    "inputFs      = 48e3\n",
    "fs           = 16e3\n",
    "numFeatures  = ffTLength//2 + 1\n",
    "numSegments  = 8\n",
    "print(\"windowLength:\",windowLength)\n",
    "print(\"overlap:\",overlap)\n",
    "print(\"ffTLength:\",ffTLength)\n",
    "print(\"inputFs:\",inputFs)\n",
    "print(\"fs:\",fs)\n",
    "print(\"numFeatures:\",numFeatures)\n",
    "print(\"numSegments:\",numSegments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_features(stft_features):\n",
    "    # Phase Aware Scaling: To avoid extreme differences (more than\n",
    "    # 45 degree) between the noisy and clean phase, the clean spectral magnitude was encoded as similar to [21]:\n",
    "    noisySTFT = np.concatenate([stft_features[:,0:numSegments-1], stft_features], axis=1)\n",
    "    stftSegments = np.zeros((numFeatures, numSegments , noisySTFT.shape[1] - numSegments + 1))\n",
    "\n",
    "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
    "        stftSegments[:,:,index] = noisySTFT[:,index:index + numSegments]\n",
    "    return stftSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [filename.split('.')[0]\n",
    "              for filename in os.listdir(\"/home/jyothish/Projects/Audio-Denoising-with-Autoencoders/data/clean/wave\")\n",
    "              if filename.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in file_names:\n",
    "    \n",
    "    signal, sr = librosa.load(\"/home/jyothish/Projects/Audio-Denoising-with-Autoencoders/data/clean/wave/\" + name + \".wav\")\n",
    "    \n",
    "    cleanAudioFeatureExtractor = FeatureExtractor(signal, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "    stft_features = cleanAudioFeatureExtractor.get_stft_spectrogram()\n",
    "    stft_features = np.abs(stft_features)   \n",
    "    \n",
    "    input_feat = prepare_input_features(stft_features)\n",
    "    input_feat = np.reshape(input_feat, (input_feat.shape[0], input_feat.shape[1], 1, input_feat.shape[2]))\n",
    "    input_feat = np.transpose(input_feat, (3, 0, 1, 2)).astype(np.float32)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
